# 编译器-编译器（Compiler-Compiler）程序设计文档

## 目录

1. [项目概述](#1-项目概述)
2. [系统设计](#2-系统设计)
   - [2.1 系统概述](#21-系统概述)
   - [2.2 架构设计](#22-架构设计)
   - [2.3 模块设计](#23-模块设计)
3. [系统实现](#3-系统实现)
   - [3.1 编译器生成器核心逻辑](#31-编译器生成器核心逻辑)
   - [3.2 同学A：词法分析器生成器实现](#32-同学a词法分析器生成器实现)
   - [3.3 同学B：语法分析器生成器实现](#33-同学b语法分析器生成器实现)
   - [3.4 同学C：代码生成器实现](#34-同学c代码生成器实现)
   - [3.5 同学D：前端接口与工具模块实现](#35-同学d前端接口与工具模块实现)
4. [系统测试](#4-系统测试)
   - [4.1 测试策略](#41-测试策略)
   - [4.2 测试用例设计](#42-测试用例设计)
   - [4.3 测试结果](#43-测试结果)
5. [AI助手使用](#5-ai助手使用)
6. [附录](#6-附录)
   - [6.1 项目文件结构](#61-项目文件结构)
   - [6.2 关键术语表](#62-关键术语表)
   - [6.3 参考资料](#63-参考资料)
   - [6.4 开发环境配置](#64-开发环境配置)
   - [6.5 常见问题解答（FAQ）](#65-常见问题解答faq)
   - [6.6 项目里程碑](#66-项目里程碑)
   - [6.7 团队分工](#67-团队分工)
   - [6.8 软件使用指南](#68-软件使用指南)

---

## 1. 项目概述

### 1.1 项目简介

本项目是一个**编译器生成器**（Compiler-Compiler），也称为"编译器的编译器"。它能够根据形式化的词法规则和语法规则自动生成完整的编译器，实现从源代码到中间代码的完整编译流程。

### 1.2 核心特性

- **自动化生成**：从规则文件自动生成词法分析器、语法分析器和代码生成器
- **语法制导翻译（SDT）**：在语法分析过程中同时生成中间代码，实现一遍扫描编译
- **模块化设计**：各模块独立实现，便于团队协作和扩展
- **完整的错误处理**：提供友好的错误提示和智能修复建议
- **多语言支持**：通过定义不同的规则文件支持多种语言

### 1.3 技术栈

- **编程语言**：Python 3.x
- **核心算法**：
  - 词法分析：正则表达式 → NFA → DFA
  - 语法分析：LL(1)递归下降解析
  - 代码生成：语法制导翻译（SDT）
- **测试框架**：pytest

---

## 2. 系统设计

### 2.1 系统概述

编译器生成器系统采用**分层架构**设计，主要分为三个层次：

1. **前端层**：负责规则文件解析和命令行接口
2. **生成器层**：负责生成词法分析器、语法分析器和代码生成器
3. **工具层**：提供日志、错误处理等通用功能

系统整体工作流程如下：

```mermaid
flowchart TD
    A["规则文件<br/>(lexer_rules.txt<br/>grammar_rules.txt)"] --> B["规则解析器<br/>(RuleParser)"]
    B --> C["词法分析器生成器<br/>(LexerGenerator)"]
    B --> D["语法分析器生成器<br/>(ParserGenerator)"]
    C --> E["生成的编译器<br/>(compiler.py)"]
    D --> E
    E --> F["源代码<br/>(source.src)"]
    F --> G["词法分析<br/>(Token流)"]
    G --> H["语法分析+代码生成<br/>(SDT)"]
    H --> I["三地址码<br/>(.tac文件)"]
```

### 2.2 架构设计

#### 2.2.1 系统架构图

```mermaid
graph TB
    subgraph "前端层 (Frontend)"
        A1["CLI接口<br/>(cli.py)"]
        A2["规则解析器<br/>(rule_parser.py)"]
    end
    
    subgraph "生成器层 (Generator)"
        B1["词法分析器生成器<br/>(lexer_generator.py)"]
        B2["语法分析器生成器<br/>(parser_generator.py)"]
        B3["代码生成器<br/>(code_generator.py)"]
    end
    
    subgraph "工具层 (Utils)"
        C1["日志系统<br/>(logger.py)"]
        C2["错误处理<br/>(error_handler.py)"]
        C3["错误格式化<br/>(error_formatter.py)"]
        C4["智能提示<br/>(smart_suggest.py)"]
    end
    
    subgraph "生成的编译器"
        D1["词法分析器"]
        D2["语法分析器"]
        D3["代码生成器"]
    end
    
    A1 --> A2
    A2 --> B1
    A2 --> B2
    A1 --> B3
    B1 --> D1
    B2 --> D2
    B3 --> D3
    A1 --> C1
    A1 --> C2
    A1 --> C3
    A1 --> C4
```

#### 2.2.2 数据流图

```mermaid
flowchart LR
    A["规则文件"] --> B["规则解析"]
    B --> C["词法规则<br/>Dict"]
    B --> D["语法规则<br/>Dict"]
    C --> E["词法分析器"]
    D --> F["语法分析器"]
    G["源代码"] --> E
    E --> H["Token流"]
    H --> F
    F --> I["AST"]
    F --> J["中间代码<br/>(SDT生成)"]
    I --> J
```

### 2.3 模块设计

#### 2.3.1 模块划分

系统主要包含以下模块：

| 模块 | 文件 | 功能描述 | 负责人 |
|------|------|----------|--------|
| 词法分析器生成器 | `lexer_generator.py` | 从正则表达式规则生成词法分析器 | 同学A |
| 语法分析器生成器 | `parser_generator.py` | 从BNF文法生成语法分析器 | 同学B |
| 代码生成器 | `code_generator.py` | 生成三地址中间代码 | 同学C |
| 规则解析器 | `rule_parser.py` | 解析词法和语法规则文件 | 同学D |
| 命令行接口 | `cli.py` | 提供用户交互接口 | 同学D |
| 工具模块 | `utils/` | 日志、错误处理等通用功能 | 同学D |

#### 2.3.2 核心模块关系图

```mermaid
classDiagram
    class CompilerCLI {
        +run(args)
        +_cmd_build()
        +_cmd_compile()
    }
    
    class RuleParser {
        +parse_lexer_rules()
        +parse_grammar_rules()
    }
    
    class LexerGenerator {
        +add_token_rule()
        +build()
        +tokenize()
    }
    
    class ParserGenerator {
        +add_production()
        +parse()
        +get_generated_code()
    }
    
    class CodeGenerator {
        +generate()
        +emit()
    }
    
    CompilerCLI --> RuleParser
    CompilerCLI --> LexerGenerator
    CompilerCLI --> ParserGenerator
    CompilerCLI --> CodeGenerator
    RuleParser --> LexerGenerator
    RuleParser --> ParserGenerator
```

---

## 3. 系统实现

### 3.1 编译器生成器核心逻辑

#### 3.1.1 整体工作流程

编译器生成器的核心逻辑遵循以下步骤：

```mermaid
sequenceDiagram
    participant User as 用户
    participant CLI as CLI接口
    participant RP as 规则解析器
    participant LG as 词法生成器
    participant PG as 语法生成器
    participant CG as 代码生成器
    participant File as 文件系统
    
    User->>CLI: python main.py build rules
    CLI->>RP: 解析规则文件
    RP->>File: 读取lexer_rules.txt
    RP->>File: 读取grammar_rules.txt
    RP-->>CLI: 返回规则字典
    
    CLI->>LG: 生成词法分析器代码
    LG-->>CLI: 返回词法分析器代码
    
    CLI->>PG: 生成语法分析器代码
    PG-->>CLI: 返回语法分析器代码
    
    CLI->>CG: 组合生成完整编译器
    CG-->>CLI: 返回完整编译器代码
    
    CLI->>File: 写入compiler.py
    CLI-->>User: 生成成功
```

#### 3.1.2 编译流程

当使用生成的编译器编译源代码时，流程如下：

```mermaid
flowchart TD
    A["源代码文件<br/>(.src)"] --> B["读取源代码"]
    B --> C["词法分析<br/>(Lexer.tokenize)"]
    C --> D["Token流"]
    D --> E["语法分析<br/>(Parser.parse)"]
    E --> F{"解析成功?"}
    F -->|"是"| G["AST + 中间代码<br/>(SDT生成)"]
    F -->|"否"| H["错误报告"]
    G --> I["输出中间代码<br/>(.tac文件)"]
    H --> J["错误格式化输出"]
```

### 3.2 同学A：词法分析器生成器实现

> **预留空间**：此部分由同学A负责实现，待补充。

### 3.3 同学B：语法分析器生成器实现

> **预留空间**：此部分由同学B负责实现，待补充。

### 3.4 同学C：代码生成器实现

> **预留空间**：此部分由同学C负责实现，待补充。

### 3.5 同学D：前端接口与工具模块实现

#### 3.5.1 规则文件解析

**规则解析器实现**

规则解析器 `RuleParser` 负责解析词法规则文件和语法规则文件，提取规则定义供生成器使用。

**关键代码实现**：

规则解析器主要包含三个方法：
- **词法规则解析**：`src/frontend/rule_parser.py:22-60` - `parse_lexer_rules()` 方法，逐行解析词法规则文件，提取token类型和正则表达式模式
- **语法规则解析**：`src/frontend/rule_parser.py:62-117` - `parse_grammar_rules()` 方法，解析BNF格式的语法规则，提取非终结符和产生式
- **符号解析辅助**：`src/frontend/rule_parser.py:119-163` - `_parse_symbols()` 方法，区分终结符（带引号）和非终结符（不带引号）

#### 3.5.1.1 规则文件格式

#### 3.5.2 命令行接口实现

**CompilerCLI类**是命令行接口的核心，负责解析参数和调度编译流程。

**CLI主入口**：`src/frontend/cli.py:46-81` - `run()` 方法，解析命令行参数并根据命令类型调用相应的处理方法。对于build命令，会调用 `_cmd_build()` 方法。

**build命令实现**：`src/frontend/cli.py:159-230` - `_cmd_build()` 方法，这是编译器生成的核心流程：

1. **读取规则文件**：调用 `load_rules_from_files()` 加载词法和语法规则
2. **生成词法分析器代码**：调用 `generate_lexer_code()` 生成词法分析器Python代码
3. **生成语法分析器代码**：调用 `generate_parser_code()` 生成语法分析器Python代码
4. **组合生成完整编译器**：调用 `generate_compiler_code()` 将词法分析器、语法分析器和代码生成器组合成完整的编译器
5. **保存到文件**：将生成的编译器代码写入指定的输出文件

**错误处理**：使用try-except捕获 `FileNotFoundError` 和其他异常，确保程序不会崩溃。

#### 3.5.2.3 Build命令错误判断实现

在编译器生成过程中（build命令），系统实现了完整的错误判断机制，确保规则文件的有效性和生成过程的可靠性。

**错误判断流程**：

```mermaid
flowchart TD
    A["开始build命令"] --> B["检查文件存在性"]
    B --> C{"文件存在?"}
    C -->|"否"| D["报告FileNotFoundError"]
    C -->|"是"| E["解析规则文件"]
    E --> F["验证词法规则格式"]
    F --> G{"格式正确?"}
    G -->|"否"| H["报告格式错误"]
    G -->|"是"| I["验证正则表达式"]
    I --> J{"正则有效?"}
    J -->|"否"| K["报告正则错误"]
    J -->|"是"| L["验证语法规则"]
    L --> M{"语法有效?"}
    M -->|"否"| N["报告语法错误"]
    M -->|"是"| O["检查输出路径"]
    O --> P{"路径可写?"}
    P -->|"否"| Q["报告路径错误"]
    P -->|"是"| R["生成编译器代码"]
    R --> S{"生成成功?"}
    S -->|"否"| T["报告生成错误"]
    S -->|"是"| U["保存编译器文件"]
    U --> V["完成"]
```

**1. 文件存在性检查**

在读取规则文件之前，系统会检查文件是否存在。如果文件不存在，会捕获 `FileNotFoundError` 异常。错误处理代码位于：`src/frontend/cli.py:502-507`

**错误处理**：
- `FileNotFoundError`：当规则文件不存在时，捕获异常并返回友好的错误信息
- `Exception`：捕获所有其他异常，确保程序不会崩溃

**2. 规则文件格式验证**

在解析规则文件时，系统会验证文件格式的正确性。

**词法规则格式验证**：

词法规则解析实现位于：`src/frontend/rule_parser.py:22-60`。该方法逐行读取文件，跳过注释和空行，按 `=` 分割提取token类型和正则表达式模式。

**验证点**：
- 检查每行是否包含 `=` 符号（规则格式标识）
- 验证 `=` 前后都有内容（token类型和正则表达式）
- 自动跳过空行和注释行（以 `#` 开头）

**语法规则格式验证**：

语法规则解析实现位于：`src/frontend/rule_parser.py:62-117`。该方法逐行读取文件，跳过注释和空行，按 `->` 分割提取非终结符和产生式，处理 `|` 分隔的多个产生式。

**验证点**：
- 检查每行是否包含 `->` 符号（产生式格式标识）
- 验证 `->` 前后都有内容（非终结符和产生式体）
- 正确处理 `|` 分隔的多个产生式
- 区分终结符（带引号）和非终结符（不带引号）

**3. 语法规则完整性验证**

系统提供了语法规则验证方法，检查所有引用的非终结符是否都已定义。实现位于：`src/frontend/rule_parser.py:166-191`。该方法收集所有已定义的非终结符，遍历每个产生式检查引用的非终结符是否都已定义。

**验证逻辑**：
- 收集所有已定义的非终结符
- 遍历每个产生式中的符号
- 对于非终结符（不带引号），检查是否在已定义集合中
- 如果发现未定义的非终结符，输出警告信息

**4. 输出路径检查**

在写入生成的编译器文件之前，系统会检查并创建输出目录。实现位于：`src/frontend/cli.py:494-497`。使用 `os.makedirs()` 自动创建输出目录，如果目录已存在不会报错。

**检查点**：
- 使用 `os.makedirs(..., exist_ok=True)` 自动创建输出目录
- 如果目录已存在，不会报错（`exist_ok=True`）
- 如果输出路径为空，使用当前目录（`.`）

**5. 生成过程异常处理**

在生成编译器代码的各个阶段，系统都会捕获异常。异常处理代码位于：`src/frontend/cli.py:502-507`。捕获 `FileNotFoundError` 和其他异常，使用Logger输出错误信息并返回非零退出码。

**异常类型**：
- **FileNotFoundError**：规则文件不存在
- **ValueError**：规则格式错误、正则表达式无效等
- **KeyError**：语法规则引用错误
- **IOError**：文件读写错误
- **其他异常**：生成过程中的其他错误

**错误信息输出**：
- 使用 `Logger` 输出结构化的错误信息
- 错误信息包含具体的错误类型和位置
- 返回非零退出码，便于脚本调用时判断成功与否

**6. 规则数量验证**

系统会检查解析后的规则数量，确保至少有一条规则。验证代码位于：`src/frontend/cli.py:189-190`。如果规则数量为0，后续生成过程会失败并报告错误。

**验证点**：
- 如果 `len(lexer_rules) == 0`，说明词法规则文件为空或格式错误
- 如果 `len(grammar_rules) == 0`，说明语法规则文件为空或格式错误
- 后续生成过程会因缺少规则而失败，系统会捕获并报告错误

**错误判断总结**：

| 检查阶段 | 检查内容 | 错误类型 | 处理方式 |
|---------|---------|---------|---------|
| 文件读取 | 文件是否存在 | `FileNotFoundError` | 捕获异常，输出错误信息 |
| 规则解析 | 规则格式是否正确 | 格式错误 | 跳过无效行，记录警告 |
| 词法规则 | 正则表达式是否有效 | `re.error` | 在生成阶段捕获 |
| 语法规则 | 非终结符是否定义 | 未定义符号 | 输出警告信息 |
| 输出路径 | 目录是否可写 | `IOError` | 自动创建目录 |
| 代码生成 | 生成过程是否成功 | 各种异常 | 捕获并报告 |


#### 3.5.2.4 命令使用说明

**配置文件说明**：

所有默认路径都在 `config.py` 中配置，可以随时修改：

```python
# config.py
DEFAULT_COMPILER = "generated/compiler.py"
DEFAULT_SOURCE_DIR = "examples/error_test"
DEFAULT_OUTPUT_DIR = "test_outputs"
DEFAULT_LEXER_RULES = "examples/pl0_subset/lexer_rules.txt"
DEFAULT_GRAMMAR_RULES = "examples/pl0_subset/grammar_rules.txt"
DEFAULT_SOURCE_FILE = "examples/pl0_subset/programs/basic_pl0.src"
```

**1. build 命令（别名：b）：生成编译器**

```bash
# 使用默认规则文件（从 config.py 读取）
python main.py b

# 使用完整命令
python main.py build

# 指定规则文件
python main.py b \
  examples/pl0_subset/lexer_rules.txt \
  examples/pl0_subset/grammar_rules.txt

# 指定输出文件
python main.py b -o generated/my_compiler.py
```

**参数说明**：
- `lexer_rules`：词法规则文件路径（可选，默认从 `config.py` 读取）
- `grammar_rules`：语法规则文件路径（可选，默认从 `config.py` 读取）
- `-o, --output`：输出文件路径（可选，默认从 `config.py` 读取）

**2. compile 命令（别名：c）：编译单个文件**

```bash
# 使用默认配置（从 config.py 读取）
python main.py c

# 使用完整命令
python main.py compile

# 指定文件
python main.py c examples/simple_expr/programs/basic_sample.src -o output.tac

# 完整命令（指定所有参数）
python main.py compile \
  examples/simple_expr/lexer_rules.txt \
  examples/simple_expr/grammar_rules.txt \
  examples/simple_expr/programs/basic_sample.src \
  -o output.tac
```

**参数说明**：
- `lexer_rules`：词法规则文件路径（可选，默认从 `config.py` 读取）
- `grammar_rules`：语法规则文件路径（可选，默认从 `config.py` 读取）
- `source`：源代码文件路径（可选，默认从 `config.py` 读取）
- `-o, --output`：输出文件路径（可选，不指定则输出到控制台）

**3. batch 命令（别名：ba）：批量编译文件夹**

```bash
# 使用默认配置（从 config.py 读取）
python main.py ba

# 使用完整命令
python main.py batch

# 指定源文件夹和输出文件夹
python main.py ba examples/error_test test_outputs/errors

# 指定所有参数
python main.py ba examples/error_test test_outputs/errors -c generated/compiler.py
```

**参数说明**：
- `source_dir`：源文件夹路径（可选，默认从 `config.py` 读取 `DEFAULT_SOURCE_DIR`）
- `output_dir`：输出文件夹路径（可选，默认从 `config.py` 读取 `DEFAULT_OUTPUT_DIR`）
- `-c, --compiler`：编译器路径（可选，默认从 `config.py` 读取 `DEFAULT_COMPILER`）

**批量编译功能特点**：
- **递归搜索**：自动搜索子文件夹中的所有 `.src` 文件
- **保持目录结构**：输出文件保持与源文件相同的目录结构
- **错误处理**：编译失败时保存详细的错误信息（英文格式）到 `_error.txt` 文件
- **统计信息**：显示编译统计（成功/失败数量）

**输出说明**：
- **编译成功**：保存为 `<output_dir>/<filename>.tac`
- **编译失败**：保存错误信息到 `<output_dir>/<filename>_error.txt`

**4. test-compiler 命令（别名：t）：批量测试**

```bash
# 使用默认配置（从 config.py 读取）
python main.py t

# 使用完整命令
python main.py test-compiler

# 指定测试目录
python main.py t -p examples/simple_expr/programs -o test_outputs
```

**参数说明**：
- `-c, --compiler-output`：生成的编译器路径（可选，默认从 `config.py` 读取）
- `-p, --program-dir`：测试程序目录（可选，默认从 `config.py` 读取）
- `-o, --output-dir`：测试输出目录（可选，默认从 `config.py` 读取）

#### 3.5.1 规则文件解析

**规则解析器实现**

规则解析器 `RuleParser` 负责解析词法规则文件和语法规则文件，提取规则定义供生成器使用。

**输入输出说明**：

**输入**：
- **词法规则文件** (`lexer_rules.txt`)：文本文件，每行定义一个token类型和对应的正则表达式模式
  - 格式：`TOKEN_TYPE = regex_pattern`
  - 支持注释（以 `#` 开头）和空行
  - 示例：`ID = [a-zA-Z_][a-zA-Z0-9_]*`
  
- **语法规则文件** (`grammar_rules.txt`)：文本文件，使用BNF格式定义语法产生式
  - 格式：`NonTerminal -> production1 | production2`
  - 终结符用单引号包围（如 `'ID'`），非终结符不带引号（如 `Expr`）
  - 支持注释（以 `#` 开头）和空行
  - 示例：`Stmt -> 'ID' 'ASSIGN' Expr 'SEMI'`

**输出**：
- **词法规则**：`List[Tuple[str, str]]` 
  - 元组列表，每个元组包含 `(token_type, regex_pattern)`
  - 示例：`[('ID', '[a-zA-Z_][a-zA-Z0-9_]*'), ('NUM', '[0-9]+'), ...]`
  
- **语法规则**：`Dict[str, List[List[str]]]`
  - 字典结构，键为非终结符名称，值为产生式列表
  - 每个产生式是一个符号列表（字符串列表）
  - 示例：`{'Stmt': [["'ID'", "'ASSIGN'", 'Expr', "'SEMI'"]], ...}`

**处理流程**：
1. **读取文件**：打开规则文件，按行读取内容
2. **过滤处理**：跳过注释行（以 `#` 开头）和空行
3. **格式解析**：
   - 词法规则：按 `=` 分割，提取token类型和正则表达式
   - 语法规则：按 `->` 分割，提取非终结符和产生式体，处理 `|` 分隔的多个产生式
4. **符号识别**：区分终结符（带引号）和非终结符（不带引号）
5. **数据结构转换**：将文本格式转换为Python数据结构
6. **返回结果**：返回给编译器生成器使用

**关键代码实现**：

规则解析器主要包含三个方法：
- **词法规则解析**：`src/frontend/rule_parser.py:22-60` - `parse_lexer_rules()` 方法，逐行解析词法规则文件，提取token类型和正则表达式模式
- **语法规则解析**：`src/frontend/rule_parser.py:62-117` - `parse_grammar_rules()` 方法，解析BNF格式的语法规则，提取非终结符和产生式
- **符号解析辅助**：`src/frontend/rule_parser.py:119-163` - `_parse_symbols()` 方法，区分终结符（带引号）和非终结符（不带引号）

#### 3.5.1.1 规则文件格式

**词法规则文件格式** (`lexer_rules.txt`)：

```
# 格式: TOKEN_TYPE = regex_pattern
# 支持标准的正则表达式语法

# 关键字（必须放在ID之前）
PRINT = print

# 标识符
ID = [a-zA-Z_][a-zA-Z0-9_]*

# 数字（整数和浮点数）
NUM = [0-9]+(?:\.[0-9]+)?

# 算术运算符
PLUS = \+
MINUS = -
MUL = \*
DIV = /

# 赋值号
ASSIGN = =

# 括号
LPAREN = \(
RPAREN = \)

# 分号
SEMI = ;
```

**语法规则文件格式** (`grammar_rules.txt`)：

```
# 格式: NonTerminal -> production1 | production2
# 使用BNF表示法
# 终结符用单引号括起来，非终结符不加引号

Program -> StmtList
StmtList -> Stmt StmtList | Stmt
Stmt -> 'ID' 'ASSIGN' Expr 'SEMI' | 'PRINT' 'LPAREN' Expr 'RPAREN' 'SEMI'
Expr -> Term AddOp | Term
AddOp -> 'PLUS' Term AddOp | 'MINUS' Term AddOp | 'PLUS' Term | 'MINUS' Term
Term -> Factor MulOp | Factor
MulOp -> 'MUL' Factor MulOp | 'DIV' Factor MulOp | 'MUL' Factor | 'DIV' Factor
Factor -> 'NUM' | 'ID' | 'LPAREN' Expr 'RPAREN'
```

#### 3.5.1.2 规则解析流程

```mermaid
flowchart TD
    A["读取规则文件"] --> B{"文件类型?"}
    B -->|"词法规则"| C["解析每行规则"]
    B -->|"语法规则"| D["解析BNF产生式"]
    C --> E["提取TOKEN_TYPE和regex"]
    D --> F["提取非终结符和产生式"]
    E --> G["返回规则列表"]
    F --> H["返回规则字典"]
```

**输入输出示例**：

**1. 词法规则解析示例**

**输入文件** (`lexer_rules.txt`)：

```
# 简单表达式语言的词法规则
# 格式: TOKEN_TYPE = regex_pattern

# 关键字（必须放在ID之前）
PRINT = print

# 标识符
ID = [a-zA-Z_][a-zA-Z0-9_]*

# 数字（整数和浮点数）
NUM = [0-9]+(?:\.[0-9]+)?

# 算术运算符
PLUS = \+
MINUS = -
MUL = \*
DIV = /

# 赋值号
ASSIGN = =

# 括号
LPAREN = \(
RPAREN = \)

# 分号
SEMI = ;
```

**解析后的输出**（Python数据结构）：

```python
[
    ('PRINT', 'print'),
    ('ID', '[a-zA-Z_][a-zA-Z0-9_]*'),
    ('NUM', '[0-9]+(?:\\.[0-9]+)?'),
    ('PLUS', '\\+'),
    ('MINUS', '-'),
    ('MUL', '\\*'),
    ('DIV', '/'),
    ('ASSIGN', '='),
    ('LPAREN', '\\('),
    ('RPAREN', '\\)'),
    ('SEMI', ';')
]
```

**说明**：
- 注释行（以 `#` 开头）和空行被自动跳过
- 每行按 `=` 分割，左侧为 token 类型，右侧为正则表达式模式
- 返回类型：`List[Tuple[str, str]]`，即 `[(token_type, regex_pattern), ...]`

**2. 语法规则解析示例**

**输入文件** (`grammar_rules.txt`)：

```
# 简单表达式语言的语法规则
# 格式: NonTerminal -> production1 | production2

# 程序：由语句组成
Program -> StmtList

# 语句列表：一个或多个语句
StmtList -> Stmt StmtList | Stmt

# 语句：赋值或打印
Stmt -> 'ID' 'ASSIGN' Expr 'SEMI' | 'PRINT' 'LPAREN' Expr 'RPAREN' 'SEMI'

# 表达式
Expr -> Term AddOp | Term

AddOp -> 'PLUS' Term AddOp | 'MINUS' Term AddOp | 'PLUS' Term | 'MINUS' Term

Term -> Factor MulOp | Factor

MulOp -> 'MUL' Factor MulOp | 'DIV' Factor MulOp | 'MUL' Factor | 'DIV' Factor

# 因子：数字、标识符或括号表达式
Factor -> 'NUM' | 'ID' | 'LPAREN' Expr 'RPAREN'
```

**解析后的输出**（Python数据结构）：

```python
{
    'Program': [
        [['StmtList']]
    ],
    'StmtList': [
        [['Stmt', 'StmtList']],
        [['Stmt']]
    ],
    'Stmt': [
        [["'ID'", "'ASSIGN'", 'Expr', "'SEMI'"]],
        [["'PRINT'", "'LPAREN'", 'Expr', "'RPAREN'", "'SEMI'"]]
    ],
    'Expr': [
        [['Term', 'AddOp']],
        [['Term']]
    ],
    'AddOp': [
        [["'PLUS'", 'Term', 'AddOp']],
        [["'MINUS'", 'Term', 'AddOp']],
        [["'PLUS'", 'Term']],
        [["'MINUS'", 'Term']]
    ],
    'Term': [
        [['Factor', 'MulOp']],
        [['Factor']]
    ],
    'MulOp': [
        [["'MUL'", 'Factor', 'MulOp']],
        [["'DIV'", 'Factor', 'MulOp']],
        [["'MUL'", 'Factor']],
        [["'DIV'", 'Factor']]
    ],
    'Factor': [
        [["'NUM'"]],
        [["'ID'"]],
        [["'LPAREN'", 'Expr', "'RPAREN'"]]
    ]
}
```

**说明**：
- 注释行（以 `#` 开头）和空行被自动跳过
- 每行按 `->` 分割，左侧为非终结符，右侧为产生式体
- 使用 `|` 分隔的多个产生式会被拆分为多个独立的产生式
- 终结符用单引号包围（如 `'ID'`），非终结符不带引号（如 `Expr`）
- 返回类型：`Dict[str, List[List[str]]]`，即 `{nonterminal: [[production1], [production2], ...]}`

**3. 符号解析细节示例**

对于产生式 `Stmt -> 'ID' 'ASSIGN' Expr 'SEMI'`，符号解析过程：

**输入字符串**：`'ID' 'ASSIGN' Expr 'SEMI'`

**解析步骤**：
1. 遇到 `'ID'`（带引号）→ 识别为终结符 → `["'ID'"]`
2. 遇到空格 → 跳过
3. 遇到 `'ASSIGN'`（带引号）→ 识别为终结符 → `["'ASSIGN'"]`
4. 遇到空格 → 跳过
5. 遇到 `Expr`（不带引号）→ 识别为非终结符 → `['Expr']`
6. 遇到空格 → 跳过
7. 遇到 `'SEMI'`（带引号）→ 识别为终结符 → `["'SEMI'"]`

**最终输出**：`["'ID'", "'ASSIGN'", 'Expr', "'SEMI'"]`

**4. 完整解析流程示例**

**调用代码**：

```python
from src.frontend.rule_parser import load_rules_from_files

lexer_rules, grammar_rules = load_rules_from_files(
    'examples/simple_expr/lexer_rules.txt',
    'examples/simple_expr/grammar_rules.txt'
)
```

**输出结果**：

```python
# lexer_rules: List[Tuple[str, str]]
# 包含 11 个词法规则

# grammar_rules: Dict[str, List[List[str]]]
# 包含 8 个非终结符的定义
# 总共 15 个产生式
```

这些解析后的数据结构将传递给编译器生成器，用于生成词法分析器和语法分析器代码。

### 3.5.2 命令行接口实现

#### 3.5.2.1 命令结构

系统提供四个主要命令，所有命令都支持最短别名：

```mermaid
graph TD
    A["main.py"] --> B["build (b)<br/>生成编译器"]
    A --> C["compile (c)<br/>编译单个文件"]
    A --> D["batch (ba)<br/>批量编译文件夹"]
    A --> E["test-compiler (t)<br/>测试编译器"]
    
    B --> B1["读取规则文件"]
    B1 --> B2["生成编译器代码"]
    B2 --> B3["保存到文件"]
    
    C --> C1["读取规则和源代码"]
    C1 --> C2["词法分析"]
    C2 --> C3["语法分析+代码生成"]
    C3 --> C4["输出中间代码"]
    
    D --> D1["扫描源文件夹"]
    D1 --> D2["批量编译所有.src文件"]
    D2 --> D3["保存结果和错误信息"]
    
    E --> E1["生成编译器"]
    E1 --> E2["批量测试程序"]
    E2 --> E3["生成测试报告"]
```

### 3.5.3 错误处理与智能提示

#### 3.5.3.1 错误处理流程

```mermaid
flowchart TD
    A["编译过程"] --> B{"错误类型?"}
    B -->|"词法错误"| C["词法错误处理"]
    B -->|"语法错误"| D["语法错误处理"]
    B -->|"语义错误"| E["语义错误处理"]
    
    C --> F["提取错误位置<br/>(行号、列号)"]
    D --> G["提取错误位置和期望token"]
    E --> H["检查未定义变量"]
    
    F --> I["格式化错误信息"]
    G --> I
    H --> J["生成智能提示"]
    I --> K["输出友好错误信息"]
    J --> K
```

#### 3.5.3.3 智能提示功能

**智能错误修复建议**：

系统实现了基于编辑距离的变量拼写错误检测和修复建议，类似现代IDE的智能提示功能。主要实现包括：
- **编辑距离计算**：`src/utils/smart_suggest.py:11-83` - 使用Levenshtein距离算法计算两个字符串的相似度
- **智能错误报告器**：`src/utils/smart_suggest.py:86-134` - `SmartErrorReporter` 类，收集已定义变量并提供修复建议

**实现逻辑**：当检测到未定义变量时，系统会计算该变量与所有已定义变量的编辑距离，选择距离最小的变量作为修复建议。

#### 3.5.3.4 错误格式化示例

系统提供友好的错误提示，包括：

- **位置信息**：精确到行号和列号
- **上下文显示**：显示错误附近的源代码
- **期望提示**：语法错误时提示期望的token
- **智能建议**：变量拼写错误时提供修复建议

**错误输出示例**：

```
语法错误: 第 3 行, 第 5 列
期望: ID, NUM, LPAREN

  1 | x = 10;
  2 | y = 20;
  3 | print(x + );
     |      ^
  4 | 
```


---

## 4. 系统测试

### 4.1 测试策略

#### 4.1.1 测试层次

系统采用**三层测试策略**：

```mermaid
graph TD
    A["测试金字塔"] --> B["单元测试<br/>(Unit Tests)"]
    A --> C["集成测试<br/>(Integration Tests)"]
    A --> D["端到端测试<br/>(E2E Tests)"]
    
    B --> B1["词法分析器测试<br/>(6个测试)"]
    B --> B2["语法分析器测试<br/>(6个测试)"]
    
    C --> C1["规则解析测试"]
    C --> C2["完整编译流程测试"]
    
    D --> D1["实际程序编译测试"]
    D --> D2["批量测试"]
```

#### 4.1.2 测试覆盖

- **单元测试**：覆盖核心模块的各个功能点
- **集成测试**：验证模块间的协作
- **端到端测试**：验证完整编译流程

### 4.2 测试用例设计

#### 4.2.1 词法分析器测试

**测试文件**：`tests/test_lexer.py`

| 测试用例 | 测试内容 | 预期结果 |
|---------|---------|---------|
| `test_add_token_rule` | 添加词法规则 | 规则成功添加 |
| `test_build_lexer` | 构建词法分析器 | 分析器构建成功 |
| `test_tokenize_simple` | 简单词法分析 | 正确识别token |
| `test_tokenize_with_whitespace` | 空白符处理 | 正确跳过空白符 |
| `test_tokenize_error` | 错误处理 | 正确报告词法错误 |
| `test_line_column_tracking` | 位置追踪 | 正确记录行号和列号 |

**测试程序示例**：

```python
def test_tokenize_simple():
    """测试简单词法分析"""
    lexer = LexerGenerator()
    lexer.add_token_rule('NUM', r'[0-9]+')
    lexer.add_token_rule('PLUS', r'\+')
    lexer.build()
    
    tokens = lexer.tokenize("1 + 2")
    assert len(tokens) == 4  # NUM, PLUS, NUM, EOF
    assert tokens[0].type == 'NUM'
    assert tokens[0].value == '1'
```

#### 4.2.2 语法分析器测试

**测试文件**：`tests/test_parser.py`

| 测试用例 | 测试内容 | 预期结果 |
|---------|---------|---------|
| `test_create_parser` | 创建解析器 | 解析器创建成功 |
| `test_add_production` | 添加产生式 | 产生式成功添加 |
| `test_parse_simple` | 简单解析 | 正确构建AST |
| `test_parse_with_alternatives` | 产生式选择 | 正确选择产生式 |
| `test_parse_error` | 语法错误 | 正确报告语法错误 |
| `test_ast_node_creation` | AST节点 | 正确创建AST节点 |

#### 4.2.3 集成测试

**测试文件**：`tests/test_integration.py`

| 测试用例 | 测试内容 | 预期结果 |
|---------|---------|---------|
| `test_end_to_end` | 完整编译流程 | 从规则文件到代码生成成功 |
| `test_rule_parser` | 规则解析 | 正确解析规则文件 |

#### 4.2.4 测试程序设计

系统提供了多个测试程序，覆盖不同的语法特性：

**1. 简单表达式语言测试程序**

| 程序文件 | 描述 | 测试重点 |
|---------|------|---------|
| `basic_sample.src` | 基础示例 | 赋值、打印、简单表达式 |
| `complex_arith.src` | 复杂算术 | 运算符优先级、括号 |
| `mixed_prints.src` | 混合打印 | 多个打印语句 |

**示例程序：`basic_sample.src`**

```c
// 基础示例
x = 10;
y = 20;
print(x + y);
```

**示例程序：`complex_arith.src`**

```c
// 复杂算术示例
a = 1 + 2 * 3;
b = (a - 4) / 2;
c = a * b + 5 - (3 / 1);
print(a + b + c);
```

**2. PL/0子集语言测试程序**

| 程序文件 | 描述 | 测试重点 |
|---------|------|---------|
| `basic_pl0.src` | 基础PL/0程序 | PL/0基本语法 |
| `if_while_pl0.src` | 控制流 | if语句、while循环 |
| `mixed_pl0.src` | 混合特性 | 综合测试 |

**3. 错误测试程序**

系统还提供了专门的错误测试程序，用于验证错误处理：

| 程序文件 | 错误类型 | 测试内容 |
|---------|---------|---------|
| `error_test.src` | 语法错误 | 缺少分号、括号不匹配等 |
| `error_undefined_var.src` | 语义错误 | 未定义变量 |
| `smart_suggest_demo1.src` | 智能提示 | 变量拼写错误 |

### 4.3 测试结果

#### 4.3.1 测试统计

运行测试命令：

```bash
python -m pytest tests/ -v
```

**测试结果统计**：

| 测试模块 | 测试数量 | 通过数量 | 状态 |
|---------|---------|---------|------|
| 词法分析器 | 6 | 6 | 全部通过 |
| 语法分析器 | 6 | 6 | 全部通过 |
| 集成测试 | 2 | 2 | 全部通过 |
| **总计** | **14** | **14** | **全部通过** |

#### 4.3.2 测试输出示例

```
tests/test_lexer.py::TestLexerGenerator::test_add_token_rule PASSED
tests/test_lexer.py::TestLexerGenerator::test_build_lexer PASSED
tests/test_lexer.py::TestLexerGenerator::test_tokenize_simple PASSED
tests/test_lexer.py::TestLexerGenerator::test_tokenize_with_whitespace PASSED
tests/test_lexer.py::TestLexerGenerator::test_tokenize_error PASSED
tests/test_lexer.py::TestLexerGenerator::test_line_column_tracking PASSED
tests/test_parser.py::TestParserGenerator::test_create_parser PASSED
tests/test_parser.py::TestParserGenerator::test_add_production PASSED
tests/test_parser.py::TestParserGenerator::test_parse_simple PASSED
tests/test_parser.py::TestParserGenerator::test_parse_with_alternatives PASSED
tests/test_parser.py::TestParserGenerator::test_parse_error PASSED
tests/test_parser.py::TestParserGenerator::test_ast_node_creation PASSED
tests/test_integration.py::TestIntegration::test_end_to_end PASSED
tests/test_integration.py::TestIntegration::test_rule_parser PASSED

======================== 14 passed in X.XXs ========================
```

#### 4.3.3 实际编译测试结果

**测试程序1：`basic_sample.src`**

源代码：
```c
// 基础示例
x = 10;
y = 20;
print(x + y);
```

生成的中间代码：
```
x = 10
y = 20
t1 = x + y
param t1
call print, 1
```

**测试程序2：`complex_arith.src`**

源代码：
```c
// 复杂算术示例
a = 1 + 2 * 3;
b = (a - 4) / 2;
c = a * b + 5 - (3 / 1);
print(a + b + c);
```

生成的中间代码：
```
a = 1
t1 = 2 * 3
a = a + t1
t2 = a - 4
b = t2 / 2
t3 = a * b
t4 = 3 / 1
t5 = t3 + 5
c = t5 - t4
t6 = a + b
t7 = t6 + c
param t7
call print, 1
```

**测试程序3：错误处理测试**

测试语法错误处理：
```c
x = 10;
y = 20;
print(x + );  // 语法错误：缺少操作数
```

错误输出：
```
语法错误: 第 3 行, 第 12 列
期望: ID, NUM, LPAREN

  1 | x = 10;
  2 | y = 20;
  3 | print(x + );
     |            ^
  4 | 
```

---

## 5. AI助手使用

### 5.1 AI助手在项目开发中的作用

本项目在开发过程中充分利用了AI助手（如Cursor、GitHub Copilot等）来提高开发效率和代码质量。AI助手在以下方面发挥了重要作用：

#### 5.1.1 代码生成与补全

- **快速生成模板代码**：根据函数签名和注释自动生成函数体框架
- **智能代码补全**：根据上下文自动补全变量名、函数调用等
- **重构建议**：提供代码重构和优化的建议

#### 5.1.2 错误诊断与修复

- **错误定位**：快速定位语法错误、类型错误等
- **修复建议**：提供具体的修复方案和代码示例
- **代码审查**：检查代码风格和潜在问题

#### 5.1.3 文档生成

- **注释生成**：根据代码自动生成函数和类的文档字符串
- **README编写**：协助编写项目文档和使用说明
- **设计文档**：帮助整理和格式化设计文档


## 6. 附录

### 6.1 项目文件结构

```
Compiler-Principles-Project/
├── docs/                          # 项目文档
│   ├── 软件设计文档.md            # 本文档
│   ├── QUICKSTART.md              # 快速开始指南
│   ├── SDT实现说明.md             # 语法制导翻译实现说明
│   └── 测试报告.md                # 测试报告
├── src/                           # 源代码
│   ├── compiler_generator/        # 编译器生成器核心
│   │   ├── lexer_generator.py     # 词法分析器生成器
│   │   ├── parser_generator.py    # 语法分析器生成器
│   │   └── code_generator.py      # 代码生成器
│   ├── frontend/                  # 前端接口
│   │   ├── cli.py                 # 命令行接口
│   │   └── rule_parser.py         # 规则解析器
│   └── utils/                     # 工具模块
│       ├── logger.py              # 日志系统
│       ├── error_handler.py       # 错误处理
│       ├── error_formatter.py     # 错误格式化
│       └── smart_suggest.py       # 智能提示
├── examples/                      # 示例语言定义
│   ├── simple_expr/               # 简单表达式语言
│   │   ├── lexer_rules.txt        # 词法规则
│   │   ├── grammar_rules.txt      # 语法规则
│   │   └── programs/              # 测试程序
│   └── pl0_subset/                # PL/0子集语言
│       ├── lexer_rules.txt
│       ├── grammar_rules.txt
│       └── programs/
├── generated/                     # 生成的编译器
│   ├── compiler.py                # 生成的编译器
│   └── compiler_simple.py        # 简单表达式编译器
├── tests/                         # 测试文件
│   ├── test_lexer.py              # 词法分析器测试
│   ├── test_parser.py              # 语法分析器测试
│   └── test_integration.py        # 集成测试
├── test_outputs/                  # 测试输出
├── main.py                        # 主程序入口
├── config.py                      # 配置文件（默认路径参数）
├── requirements.txt               # 项目依赖
└── README.md                      # 项目说明
```

### 6.2 关键术语表

| 术语 | 英文 | 说明 |
|------|------|------|
| 编译器生成器 | Compiler-Compiler | 能够根据规则文件自动生成编译器的工具 |
| 词法分析 | Lexical Analysis | 将源代码转换为token流的过程 |
| 语法分析 | Syntax Analysis | 根据语法规则构建抽象语法树的过程 |
| 语法制导翻译 | Syntax-Directed Translation (SDT) | 在语法分析过程中同时生成中间代码的技术 |
| 三地址码 | Three-Address Code | 一种中间代码表示形式 |
| 抽象语法树 | Abstract Syntax Tree (AST) | 表示程序语法结构的树形数据结构 |
| 产生式 | Production | 文法规则，定义如何从非终结符推导出符号序列 |
| 非终结符 | Non-terminal | 文法中可以进一步展开的符号 |
| 终结符 | Terminal | 文法中的基本符号，不能再展开 |
| FIRST集合 | FIRST Set | 从某个符号开始可以推导出的第一个终结符集合 |
| FOLLOW集合 | FOLLOW Set | 某个非终结符后面可能出现的终结符集合 |

### 6.3 参考资料

1. **编译原理教材**
   - 《编译原理》（龙书）- Aho, Lam, Sethi, Ullman
   - 《现代编译原理》- Andrew W. Appel

2. **相关工具**
   - [ANTLR](https://www.antlr.org/) - 语法分析器生成器
   - [Lex/Yacc](https://en.wikipedia.org/wiki/Yacc) - 经典的词法和语法分析器生成器
   - [PLY](https://www.dabeaz.com/ply/) - Python的Lex/Yacc实现

3. **在线资源**
   - [正则表达式教程](https://regex101.com/)
   - [BNF范式说明](https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form)
   - [语法制导翻译](https://en.wikipedia.org/wiki/Syntax-directed_translation)

### 6.4 开发环境配置

#### 6.4.1 环境要求

- **Python版本**：Python 3.7+
- **操作系统**：Windows / Linux / macOS
- **依赖包**：见 `requirements.txt`

#### 6.4.2 安装步骤

```bash
# 1. 克隆项目（如果使用Git）
git clone <repository-url>
cd Compiler-Principles-Project

# 2. 创建虚拟环境（推荐）
python -m venv venv
source venv/bin/activate  # Linux/macOS
# 或
venv\Scripts\activate  # Windows

# 3. 安装依赖
pip install -r requirements.txt

# 4. 运行测试
python -m pytest tests/ -v
```

#### 6.4.3 开发工具推荐

- **IDE**：VS Code、PyCharm
- **AI助手**：Cursor、GitHub Copilot
- **版本控制**：Git
- **测试框架**：pytest

### 6.5 常见问题解答（FAQ）

**Q1: 如何添加新的语言支持？**

A: 创建新的规则文件目录，编写 `lexer_rules.txt` 和 `grammar_rules.txt`，然后使用 `build` 命令生成编译器。

**Q2: 生成的编译器如何使用？**

A: 使用 `python generated/compiler.py <source_file> -o <output_file>` 命令编译源代码。

**Q3: 如何调试规则文件中的错误？**

A: 检查正则表达式语法，确保BNF格式正确，使用测试程序逐步验证。

**Q4: 支持哪些语法特性？**

A: 支持表达式、赋值、打印、条件语句、循环等，具体取决于语法规则文件的定义。

**Q5: 如何扩展代码生成功能？**

A: 修改 `code_generator.py` 中的代码生成逻辑，或修改 `parser_generator.py` 中的SDT翻译动作。

### 6.6 项目里程碑

| 时间 | 里程碑 | 说明 |
|------|--------|------|
| 第1周 | 项目启动 | 确定需求，设计架构 |
| 第2周 | 词法分析器 | 完成词法分析器生成器 |
| 第3周 | 语法分析器 | 完成语法分析器生成器 |
| 第4周 | 代码生成器 | 完成代码生成器，实现SDT |
| 第5周 | 集成测试 | 完成集成测试，修复bug |
| 第6周 | 文档完善 | 完成文档编写，项目总结 |

### 6.7 团队分工

| 成员 | 负责模块 | 主要工作 |
|------|---------|---------|
| 同学A | 词法分析器生成器 | 实现正则表达式到DFA的转换 |
| 同学B | 语法分析器生成器 | 实现LL(1)解析和SDT |
| 同学C | 代码生成器 | 实现三地址码生成 |
| 同学D | 前端接口、工具模块、测试、文档 | CLI、规则解析、错误处理、批量编译、测试用例、文档编写等 |

### 6.8 软件使用指南

#### 6.8.1 快速开始

**1. 环境准备**

```bash
# 安装依赖
pip install -r requirements.txt
```

**2. 配置文件说明**

编辑 `config.py` 文件可以修改所有默认路径：

```python
# config.py
DEFAULT_COMPILER = "generated/compiler.py"          # 默认生成的编译器路径
DEFAULT_SOURCE_DIR = "examples/error_test"          # 默认源文件夹
DEFAULT_OUTPUT_DIR = "test_outputs"                 # 默认输出文件夹
DEFAULT_LEXER_RULES = "examples/pl0_subset/lexer_rules.txt"      # 默认词法规则
DEFAULT_GRAMMAR_RULES = "examples/pl0_subset/grammar_rules.txt" # 默认语法规则
DEFAULT_SOURCE_FILE = "examples/pl0_subset/programs/basic_pl0.src" # 默认源文件
```

#### 6.8.2 命令详解

**命令别名对照表**：

| 完整命令 | 简化命令 | 功能说明 |
|---------|---------|---------|
| `build` | `b` | 从规则文件生成编译器 |
| `compile` | `c` | 编译单个源代码文件 |
| `batch` | `ba` | 批量编译文件夹中的所有 `.src` 文件 |
| `test-compiler` | `t` | 批量测试生成的编译器 |

**1. 生成编译器**

```bash
# 方式1：使用默认配置（最短命令）
python main.py b

# 方式2：指定规则文件
python main.py b examples/pl0_subset/lexer_rules.txt examples/pl0_subset/grammar_rules.txt

# 方式3：指定输出文件
python main.py b -o generated/my_compiler.py

# 方式4：完整命令
python main.py build \
  examples/pl0_subset/lexer_rules.txt \
  examples/pl0_subset/grammar_rules.txt \
  -o generated/compiler_pl0.py
```

**2. 编译单个文件**

```bash
# 方式1：使用默认配置（最短命令）
python main.py c

# 方式2：指定源文件
python main.py c examples/simple_expr/programs/basic_sample.src -o output.tac

# 方式3：完整命令
python main.py compile \
  examples/simple_expr/lexer_rules.txt \
  examples/simple_expr/grammar_rules.txt \
  examples/simple_expr/programs/basic_sample.src \
  -o output.tac
```

**3. 批量编译（推荐用于测试）**

```bash
# 方式1：使用默认配置（最短命令）
python main.py ba

# 方式2：指定源文件夹和输出文件夹
python main.py ba examples/error_test test_outputs/errors

# 方式3：指定所有参数
python main.py ba examples/error_test test_outputs/errors -c generated/compiler.py

# 方式4：完整命令
python main.py batch \
  examples/error_test \
  test_outputs/errors \
  -c generated/compiler.py
```

**批量编译输出说明**：
- 编译成功：生成 `<filename>.tac` 文件
- 编译失败：生成 `<filename>_error.txt` 文件，包含详细错误信息（英文格式）

**4. 测试编译器**

```bash
# 方式1：使用默认配置（最短命令）
python main.py t

# 方式2：指定测试目录
python main.py t -p examples/simple_expr/programs -o test_outputs

# 方式3：完整命令
python main.py test-compiler \
  examples/simple_expr/lexer_rules.txt \
  examples/simple_expr/grammar_rules.txt \
  -p examples/simple_expr/programs \
  -o test_outputs
```

#### 6.8.3 典型使用场景

**场景1：快速测试新语言规则**

```bash
# 1. 编辑规则文件
# examples/my_lang/lexer_rules.txt
# examples/my_lang/grammar_rules.txt

# 2. 生成编译器
python main.py b examples/my_lang/lexer_rules.txt examples/my_lang/grammar_rules.txt

# 3. 测试单个文件
python main.py c examples/my_lang/test.src -o test.tac
```

**场景2：批量测试错误处理**

```bash
# 1. 准备错误测试文件（放在 examples/error_test/ 目录）
# error1.src, error2.src, ...

# 2. 批量编译并查看错误信息
python main.py ba examples/error_test test_outputs/errors

# 3. 查看错误文件
# test_outputs/errors/error1_error.txt
# test_outputs/errors/error2_error.txt
```

**场景3：完整编译流程**

```bash
# 1. 生成编译器
python main.py b examples/pl0_subset/lexer_rules.txt examples/pl0_subset/grammar_rules.txt

# 2. 批量编译所有程序
python main.py ba examples/pl0_subset/programs test_outputs/pl0_programs

# 3. 查看编译结果
ls test_outputs/pl0_programs/*.tac
```

#### 6.8.4 错误信息说明

所有错误信息使用英文格式，避免编码问题。错误信息包含：

1. **错误类型**：Syntax Error（语法错误）或 Lexical Error（词法错误）
2. **错误位置**：文件路径、行号、列号
3. **源代码片段**：显示错误前后各2行代码
4. **错误详情**：具体错误描述
5. **修复建议**：智能建议可能的修复方法

**示例错误输出**：

```
======================================================================
[ERROR] Syntax Error
======================================================================

[Location] File: test.src, Line 3, Column 12

[Source Code Snippet]:
----------------------------------------------------------------------
       1 | x = 10;
       2 | y = 20;
>>>    3 | print(x + );  // Missing operand
            ^
       4 | 
----------------------------------------------------------------------

[Error Details]:
   Syntax error at line 3, column 12
  Expected: ID, NUM, LPAREN

[Suggestions]:
   - Please check if the grammar rules are correct
   - Make sure no necessary symbols are missing
======================================================================
```

#### 6.8.5 常见问题

**Q1: 如何修改默认配置？**

A: 直接编辑 `config.py` 文件，修改相应的默认路径即可。

**Q2: 批量编译时如何只编译特定文件？**

A: 批量编译会编译文件夹中所有 `.src` 文件。如需选择性编译，可以：
- 将需要编译的文件放在单独文件夹
- 或使用 `compile` 命令逐个编译

**Q3: 生成的编译器如何使用？**

A: 生成的编译器是一个独立的 Python 脚本，可以直接运行：

```bash
python generated/compiler.py source.src -o output.tac
```

**Q4: 如何查看命令帮助？**

A: 使用 `--help` 参数：

```bash
python main.py --help
python main.py b --help
python main.py ba --help
```

